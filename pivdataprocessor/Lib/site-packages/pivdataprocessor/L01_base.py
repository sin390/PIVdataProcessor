''' The base class of PIVDataProcessor seriers.

This class is intented NOT to be instantiated.
Instead, it performs some preliminary operations on the data in the form of class functions.

Note that:
* This program is an object-oriented remake of its origin version written in Fortran by Dr. Prof. WATANABE.
* This code should work well with python 3.12.

=========================
= Author:   HAN Zexu    =
= Version:  2.2         =
= Date:     2025/05/22  =
=========================
'''

# -------------------------------------------------------------------------
# 01. import libraries
# region

import pandas as pd
import numpy as np

import os
import sys
import shutil
import pickle
from dataclasses import dataclass, asdict, fields
import yaml

from .A01_toolbox import float_precsion as float_precsion
from .A01_toolbox import lagrange_interpolate_2D_4points_scalar
from .A01_toolbox import scalar_field_5points_stencil

# endregion

# -------------------------------------------------------------------------
# 02. Basic parameters
# region
@dataclass
class GeneralDataHandler():
    def to_yaml(self, filename:str):
        with open(filename, "w", encoding="utf-8") as f:
            yaml.dump(asdict(self), f, default_flow_style=False)     
    
    @classmethod
    def from_yaml(cls, filename: str):
        if not os.path.exists(filename):
            print(f"Warning: {filename} not found, using default values.")
            return cls()

        with open(filename, "r", encoding="utf-8") as f:
            data = yaml.load(f, Loader=yaml.FullLoader)

        valid_keys = {f.name for f in fields(cls)}
        filtered_data = {k: v for k, v in data.items() if k in valid_keys}

        return cls(**{**asdict(cls()), **filtered_data})
        

@dataclass
class CaseInfoClass(GeneralDataHandler):
    CaseName:str = None
    
    'Grid information'
    Nx: int = 80
    Ny: int = 50
    dir_scale: tuple = (1.0, -1.0)

    'Range settings'
    Central_Position_Grid: tuple = (0,0)
    Central_Position_Flow: tuple = (0,0)

    Effective_Range: tuple[tuple[int, int], tuple[int, int]] = ((0, 0), (0, 0)) 
    Uniform_Range: tuple[tuple[int, int], tuple[int, int]] = ((0, 0), (0, 0))


class PIVDataProcessorPaths:
    '''
        Some parameters which will not be modified across the processing.
    '''

    'Saving path'
    Working_path: str = os.getcwd()
    Plot_foldername:str = "/S02_Plots"
    Case_foldername: str = "/S01_Cases"
    Raw_data_foldername: str = "/01_Raw_Data"
    Processed_data_foldername: str =  "/02_Processed_Data"
    Log_file_name: str = '/Log.txt'
    Caseinfo_file_name: str = '/CaseInfo.yaml'

    Run_path_rootword: str = "/Run"         # i.e /RunN, where N is the sequence number.
    Framedatafile_rootword: str = "/No_"         # i.e /No_N, where N is the sequence number.

    def __init__(self) -> None:
        pass   

# -------------------------------------------------------------------------
# End of Basic parameters
# endregion

# -------------------------------------------------------------------------
# 03. pBase
# region
class PIVDataProcessorBase:
    # -------------------------------------------------------------------------
    # Variable statements
    # region 

    'Parameters'
    Paths = PIVDataProcessorPaths()
    CaseInfo = CaseInfoClass()

    'Results'
    'X[0] -> x(i,j), X[1] -> y(i,j)'    
    X = np.zeros((2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    dX = np.zeros((2), dtype=float_precsion)
    
    'U[0] -> u(i,j), U[1] -> v(i,j)'
    U = np.zeros((2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    avg_U = np.zeros((2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    fluc_U = np.zeros((2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    
    'dUdX[0][0] -> du/dx, dUdX[1][0] -> dv/dx'
    'dUdX[0][1] -> du/dy, dUdX[1][1] -> dv/dy' 
    dUdX = np.zeros((2, 2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    avg_dUdX = np.zeros((2, 2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    fluc_dUdX = np.zeros((2, 2, CaseInfo.Nx, CaseInfo.Ny), dtype=float_precsion)
    
    'loop control'
    frame_numbers_in_runs = []

    # -------------------------------------------------------------------------
    # End of Variable statements
    # endregion
     
    def __init__(self) -> None:
        pass

    # -------------------------------------------------------------------------
    # Case manager
    # region 

    @classmethod
    def create_case(cls, casename:str, Nx:int = 80, Ny:int = 50) -> None:
        cls.CaseInfo.CaseName = casename
        cls.CaseInfo.Nx = Nx
        cls.CaseInfo.Ny = Ny
        paths = cls.get_paths()
        if not os.path.exists(paths['CaseBase']):
            os.mkdir(paths['CaseBase'])
        if not os.path.exists(paths['CurrentCase']):
            os.mkdir(paths['CurrentCase'])        
        cls.__check_path()
        cls.CaseInfo.to_yaml(paths['CaseInfo'])

    @classmethod
    def save_case(cls) -> None:
        paths = cls.get_paths()
        cls.CaseInfo.to_yaml(paths['CaseInfo'])

    @classmethod
    def load_case(cls, casename:str, ifinit = False) -> None:
        caseinfofile = cls.Paths.Working_path + cls.Paths.Case_foldername + '/' + casename + '/' + cls.Paths.Caseinfo_file_name
        cls.CaseInfo = CaseInfoClass.from_yaml(caseinfofile)
        
        cls.X = np.zeros((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)
        cls.dX = np.zeros((2), dtype=float_precsion)
        cls.U = np.zeros((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)
        cls.avg_U = np.zeros((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)
        cls.fluc_U = np.zeros((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)

        cls.dUdX = np.zeros((2, 2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)
        cls.avg_dUdX = np.zeros((2, 2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)
        cls.fluc_dUdX = np.zeros((2, 2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion)

        if ifinit == False:
            cls.base_load_data_all(0,0)
 
    # -------------------------------------------------------------------------
    # End of Case manager
    # endregion

    # -------------------------------------------------------------------------
    # Some initialization operations
    # region 

    @classmethod
    def __check_path(cls) -> None:
        '''
            If any specific data path does not exist, create it.

            This is an auxiliary function. No need to pay extra attention.
        '''

        paths = cls.get_paths()

        # /01_Raw_Data
        if not os.path.exists(paths['RawData']):
            os.mkdir(paths['RawData'])
            os.mkdir(paths['RawData'] + "/csv")
        elif os.listdir(paths['RawData']):
            cls.pBasereport("[Raw_data_path] is not empty.")
        
        # /02_Processed_Data
        if not os.path.exists(paths['ProcessedData']):
            os.mkdir(paths['ProcessedData'])
        else:
            cls.rm_and_create_directory(paths['ProcessedData'])    

                # /log.txt
        if os.path.exists(paths['LogFile']):
            os.remove(paths['LogFile'])      

    @classmethod
    def __from_csv_to_bin(cls) -> None:
        '''
            Convert the raw data file from .csv to .bin format.
            
            Assuming that .csv files are stored in /{Raw_data_path}/csv,
            results are stored in /{Raw_data_path}/bin.

            !!! This is an auxiliary function but vital. 
            You should pay attention here to the name format of data file and directory.
        '''
        def csv_rundirID_name_rule(run_name:str)->int:
            csv_rundirID = int(run_name[3:])
            return csv_rundirID
        def csv_datafileID_name_rule(file_name:str)->int:
            frame_id = int(file_name.split('.')[-2])
            return frame_id

        paths = cls.get_paths()
        csv_path = paths['RawData'] + "/csv"
        bin_path = paths['RawData'] + "/bin"
 
        head_line_number = 5
        
        x_label = 'x (mm)[mm]'
        y_label = 'y (mm)[mm]'
        u_label = 'U[m/s]'
        v_label = 'V[m/s]'
        dtype = {x_label: float_precsion, y_label: float_precsion, u_label:float_precsion, v_label:float_precsion}

        tmp_X = cls.get_a_container(1)
        tmp_U = cls.get_a_container(1)

        cls.rm_and_create_directory(bin_path)       
        run_names = [run_name for run_name in os.listdir(csv_path) if os.path.isdir(os.path.join(csv_path, run_name))]
        cls.frame_numbers_in_runs = list(range(len(run_names)))
        for run_name in run_names:
            cls.pBasereport(f"converting {run_name}")
            run_dir_in_csv_path = os.path.join(csv_path, run_name)
            
            # Pay attention to the format here!
            run_id = csv_rundirID_name_rule(run_name)
            # ========================

            formatted_run_name = cls.Paths.Run_path_rootword + f"{run_id}"
            run_dir_in_bin_path = bin_path + formatted_run_name
            os.mkdir(run_dir_in_bin_path)
            os.mkdir(run_dir_in_bin_path + '/Raw_X')
            os.mkdir(run_dir_in_bin_path + '/Raw_U')             
            
            file_names = [file_name for file_name in os.listdir(run_dir_in_csv_path) if file_name.endswith('.csv')]
            for file_name in file_names:
                csv_file = os.path.join(run_dir_in_csv_path, file_name)
                df = pd.read_csv(csv_file, dtype=dtype, skiprows = head_line_number)
                tmp_X[0] = df[x_label].values.reshape((cls.CaseInfo.Nx, cls.CaseInfo.Ny), order='F')
                tmp_X[1] = df[y_label].values.reshape((cls.CaseInfo.Nx, cls.CaseInfo.Ny), order='F')
                tmp_U[0] = df[u_label].values.reshape((cls.CaseInfo.Nx, cls.CaseInfo.Ny), order='F')
                tmp_U[1] = df[v_label].values.reshape((cls.CaseInfo.Nx, cls.CaseInfo.Ny), order='F')

                # Pay attention here. Related to the naming format of .csv files.
                frame_id = csv_datafileID_name_rule(file_name)
                # ====

                # Align the direction of coordinate.
                for i in range(2):
                    tmp_X[i] = tmp_X[i] * cls.CaseInfo.dir_scale[i]
                    tmp_U[i] = tmp_U[i] * cls.CaseInfo.dir_scale[i]
                    if cls.CaseInfo.dir_scale[0] < 0:
                        tmp_X[i] = tmp_X[i][::-1]
                        tmp_U[i] = tmp_U[i][::-1]
                    if cls.CaseInfo.dir_scale[1] < 0:
                        tmp_X[i] = tmp_X[i][:,::-1]
                        tmp_U[i] = tmp_U[i][:,::-1]

                bin_file = run_dir_in_bin_path + '/Raw_X' + cls.Paths.Framedatafile_rootword + f"{frame_id}.bin"
                cls.save_nparray_to_bin(tmp_X,bin_file)
                bin_file = run_dir_in_bin_path + '/Raw_U' + cls.Paths.Framedatafile_rootword + f"{frame_id}.bin"
                cls.save_nparray_to_bin(tmp_U,bin_file)
            cls.frame_numbers_in_runs[run_id] = len(file_names)
           
    @classmethod
    def __interpolate_raw_to_unifrom_grid(cls) -> None:
        '''
        Interpolate the raw data on non-uniform spaced grid to uniform grid.

        !!! This is a core function.
        '''
        
        # Prepare paths.
        paths = cls.get_paths()
        Raw_bin_data_path = paths['RawData'] + "/bin"
        Preprocessed_data_path = paths['ProcessedData']
        cls.rm_and_create_directory(Preprocessed_data_path)
        #====

        # [0][0] = x_min, [0][1] = x_max, [1][0] = y_min, [1][1] = y_max
        maxmin_X_across_runs = np.zeros((2,2), dtype = float_precsion)
        
        # Generate the uniform grid.
        for ID_run in range(len(cls.frame_numbers_in_runs)):
            current_raw_bin_run_path = Raw_bin_data_path + cls.Paths.Run_path_rootword + f'{ID_run}'

            # Only read the first frame, assuming that all frames in one run share the same grid. 
            X_bin_path = current_raw_bin_run_path + "/Raw_X" + cls.Paths.Framedatafile_rootword + f'0.bin'
            with open(X_bin_path, 'rb') as f:
                tmp_X = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))
            
            if ID_run == 0:
                for i in range(2):
                    maxmin_X_across_runs[i][0] = tmp_X[i][0][0]
                    maxmin_X_across_runs[i][1] = tmp_X[i][-1][-1]
            else:
                for i in range(2):
                    maxmin_X_across_runs[i][0] = max(tmp_X[i][0][0], maxmin_X_across_runs[i][0])
                    maxmin_X_across_runs[i][1] = min(tmp_X[i][-1][-1], maxmin_X_across_runs[i][1])
        for i in range(2):
            tmp_X_scale = np.linspace(maxmin_X_across_runs[0][0], maxmin_X_across_runs[0][1], cls.CaseInfo.Nx)
            tmp_Y_scale = np.linspace(maxmin_X_across_runs[1][0], maxmin_X_across_runs[1][1], cls.CaseInfo.Ny)
        uniform_x, uniform_y = np.meshgrid(tmp_X_scale, tmp_Y_scale)
        uniform_X_container = cls.get_a_container(1)
        uniform_X_container[0, :, :] = uniform_x.T
        uniform_X_container[1, :, :] = uniform_y.T
        cls.X = uniform_X_container
        cls.dX[0] = cls.X[0][1,1]-cls.X[0][0,0]
        cls.dX[1] = cls.X[1][1,1]-cls.X[1][0,0]

        output_X_path = Preprocessed_data_path + "/X"
        os.mkdir(output_X_path)
        output_X_file = output_X_path + '/uniform_gird_X.bin'
        cls.save_nparray_to_bin(cls.X,output_X_file)
        output_dX_file = output_X_path + '/uniform_gird_dX.bin'
        cls.save_nparray_to_bin(cls.dX,output_dX_file)
        #====
        cls.pBasereport("Interpolating raw data into uniform grid...")        
        output_U_path = Preprocessed_data_path + "/U"
        os.mkdir(output_U_path)
        tmp_U_interpolated = cls.get_a_container(1)
        for ID_run in range(len(cls.frame_numbers_in_runs)):
            cls.pBasereport(f"Run{ID_run}")          
            output_U_run_path = output_U_path + cls.Paths.Run_path_rootword+ f"{ID_run}"           
            os.mkdir(output_U_run_path)

            read_run_path = paths['RawData'] + '/bin' + cls.Paths.Run_path_rootword+ f"{ID_run}"            
            read_X_path = read_run_path + "/Raw_X"
            read_U_path = read_run_path + "/Raw_U"
            for ID_frame in range(cls.frame_numbers_in_runs[ID_run]):
                datafile_name = cls.Paths.Framedatafile_rootword + f"{ID_frame}.bin"

                raw_data_X_file = read_X_path + datafile_name
                raw_data_U_file = read_U_path + datafile_name
                output_U_file = output_U_run_path + datafile_name

                with open(raw_data_X_file, 'rb') as f:
                    tmp_X_raw = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))
                with open(raw_data_U_file, 'rb') as f:
                    tmp_U_raw = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))

                for i in range(2):          
                    tmp_U_interpolated[i] = lagrange_interpolate_2D_4points_scalar(grid1=tmp_X_raw, grid2=uniform_X_container, scalar1=tmp_U_raw[i])
                cls.save_nparray_to_bin(tmp_U_interpolated, output_U_file)
        cls.pBasereport("Interpolation completed.")   

    # -------------------------------------------------------------------------
    # End of Some initialization operations
    # endregion 

    # -------------------------------------------------------------------------
    # Some basic calculation
    # region 
    @classmethod
    def __cal_avg_U(cls) -> None:
        paths = cls.get_paths()
        os.mkdir(paths['ProcessedData'] + '/avg_U')
        avg_U = cls.get_a_container(1)
        for i in range(len(cls.frame_numbers_in_runs)):
            run_path = paths['ProcessedData'] + '/U' + cls.Paths.Run_path_rootword + f'{i}'
            for j in range(cls.frame_numbers_in_runs[i]):                
                frame_file = run_path + cls.Paths.Framedatafile_rootword + f'{j}.bin'
                frame_U = cls.get_a_container(1)
                frame_U = cls.load_nparray_from_bin(frame_U,frame_file)
                avg_U = avg_U + frame_U
        cls.avg_U = avg_U/float(sum(cls.frame_numbers_in_runs))
        data_rootpath = paths['ProcessedData']
        avg_U_flie = data_rootpath + '/avg_U' + '/avg_U.bin'
        cls.save_nparray_to_bin(cls.avg_U, avg_U_flie)

    @classmethod
    def __cal_fluc_U(cls) -> None:
        paths = cls.get_paths()
        os.mkdir(paths['ProcessedData'] + '/fluc_U')
        for i in range(len(cls.frame_numbers_in_runs)):
            U_run_path = paths['ProcessedData'] + '/U' + cls.Paths.Run_path_rootword + f'{i}'
            fluc_U_run_path = paths['ProcessedData'] + '/fluc_U' + cls.Paths.Run_path_rootword + f'{i}'
            os.mkdir(fluc_U_run_path)
            for j in range(cls.frame_numbers_in_runs[i]):                
                frame_file = U_run_path + cls.Paths.Framedatafile_rootword + f'{j}.bin'
                frame_U = cls.get_a_container(1)
                frame_U = cls.load_nparray_from_bin(frame_U, frame_file)
                cls.fluc_U = frame_U - cls.avg_U
                fluc_U_file = fluc_U_run_path + cls.Paths.Framedatafile_rootword + f'{j}.bin'
                cls.save_nparray_to_bin(cls.fluc_U,fluc_U_file)

    @classmethod
    def __cal_dUdX(cls) -> None:
        paths = cls.get_paths()
        dx_in_m = cls.dX/1000
        os.mkdir(paths['ProcessedData'] + '/avg_dUdX')
        os.mkdir(paths['ProcessedData'] + '/fluc_dUdX')
        os.mkdir(paths['ProcessedData'] + '/dUdX')
        cls.avg_dUdX[0] = scalar_field_5points_stencil(cls.avg_U[0],dx_in_m[0],dx_in_m[1])
        cls.avg_dUdX[1] = scalar_field_5points_stencil(cls.avg_U[1],dx_in_m[0],dx_in_m[1])
        data_rootpath = paths['ProcessedData']
        avg_dUdX_flie = data_rootpath + '/avg_dUdX' + '/avg_dUdX.bin'
        cls.save_nparray_to_bin(cls.avg_dUdX, avg_dUdX_flie)

        'Instantaneous'
        for ID_run in range(len(cls.frame_numbers_in_runs)):
            run_path = cls.Paths.Run_path_rootword + f'{ID_run}'
            dUdX_run_path = data_rootpath + '/dUdX' + cls.Paths.Run_path_rootword + f'{ID_run}'
            fluc_dUdX_run_path = data_rootpath + '/fluc_dUdX' + cls.Paths.Run_path_rootword + f'{ID_run}'
            os.mkdir(dUdX_run_path)
            os.mkdir(fluc_dUdX_run_path)
            for ID_frame in range(cls.frame_numbers_in_runs[ID_run]):   
                frame_name = cls.Paths.Framedatafile_rootword + f'{ID_frame}.bin'             
                dUdX_file = dUdX_run_path +  cls.Paths.Framedatafile_rootword + f'{ID_frame}.bin'
                fluc_dUdX_file = fluc_dUdX_run_path + cls.Paths.Framedatafile_rootword + f'{ID_frame}.bin'                
                
                U_file = data_rootpath + '/U' + run_path + frame_name                
                with open(U_file, 'rb') as f:
                    U = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))
                cls.dUdX[0] = scalar_field_5points_stencil(U[0],dx_in_m[0],dx_in_m[1])
                cls.dUdX[1] = scalar_field_5points_stencil(U[1],dx_in_m[0],dx_in_m[1])
                cls.save_nparray_to_bin(cls.dUdX, dUdX_file)

                fluc_U_file = data_rootpath + '/fluc_U' + run_path + frame_name
                with open(fluc_U_file, 'rb') as f:
                    fluc_U = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny)) 
                cls.fluc_dUdX[0] = scalar_field_5points_stencil(fluc_U[0],dx_in_m[0],dx_in_m[1])
                cls.fluc_dUdX[1] = scalar_field_5points_stencil(fluc_U[1],dx_in_m[0],dx_in_m[1])
                cls.save_nparray_to_bin(cls.fluc_dUdX, fluc_dUdX_file)
                    
    @classmethod
    def __find_central_position(cls):
        central_index = [0,0]
        tmp_x = abs(cls.X[1][0][0])
        tmp_x_index = 0
        for i in range(0,cls.CaseInfo.Nx):
            if (abs(cls.X[0][i][0]) < tmp_x):
                tmp_x_index = i
                tmp_x = abs(cls.X[0][i][0])
        central_index[0] = tmp_x_index

        tmp_y = abs(cls.X[1][0][0])
        tmp_y_index = 0
        for i in range(0,cls.CaseInfo.Ny):
            if ( abs(cls.X[1][0][i]) < tmp_y):
                tmp_y_index = i
                tmp_y = abs(cls.X[1][0][i]) 
        central_index[1] = tmp_y_index
        
        cls.CaseInfo.Central_Position_Grid = tuple(central_index)
        cls.save_case()

    # -------------------------------------------------------------------------
    # End of Some basic calculation
    # endregion 

    # -------------------------------------------------------------------------
    # Main Function
    # region 
    @classmethod
    def preprocess_data(cls, casename:str, ifbin = False) -> None:
        cls.load_case(casename=casename, ifinit=True)
        if ifbin == False:
            cls.__check_path()
            cls.__from_csv_to_bin()
        cls.__interpolate_raw_to_unifrom_grid()
        cls.__cal_avg_U()
        cls.__cal_fluc_U()
        cls.__cal_dUdX()
        cls.__find_central_position()

        paths = cls.get_paths()
        with open(paths['ProcessedData']+'/frame_numbers_in_runs.pkl','wb') as f:
            pickle.dump(cls.frame_numbers_in_runs,f)
    
        cls.pBasereport(f'--Procession completed!--\n \
                    Casename: {casename}\n\
                    Total Number of Sample Frames:{sum(cls.frame_numbers_in_runs)}')
    # -------------------------------------------------------------------------
    # End of Main Function
    # endregion 

    # -------------------------------------------------------------------------
    # Some tool functions
    # region
    @classmethod
    def __pos_mm_to_index(cls, x_mm, y_mm):
        X = cls.X[0][:,0]
        Y = cls.X[1][0,:]
        idx = np.argmin(np.abs(X - x_mm))
        idy = np.argmin(np.abs(Y - y_mm))
        return int(idx), int(idy)
    @classmethod
    def pos_mm_to_index_list(cls, x_list, y_list):
        x_index = []
        y_index = []
        for i in range(len(x_list)):
            tmp_x_i, tmp_y_i = cls.__pos_mm_to_index(x_list[i],0)
            x_index.append(tmp_x_i)
        for i in range(len(y_list)):
            tmp_x_i, tmp_y_i = cls.__pos_mm_to_index(0,y_list[i])
            y_index.append(tmp_y_i)
        return x_index, y_index


    @classmethod
    def pBasereport(cls, str:str = '', logfile:str = '') -> None:
        '''
            Custom print().

            No need to pay extra attention.
        '''
        if logfile == '':
            logfile = cls.get_paths()['LogFile']
        with open(logfile,'a') as f:
            sys.stdout = f
            print(str)
        sys.stdout = sys.__stdout__
    
    @classmethod
    def rm_and_create_directory(cls, path_to_directory:str, ifcreate = True) -> None:
        if os.path.exists(path_to_directory):
            shutil.rmtree(path_to_directory)
        if ifcreate == True:
            os.makedirs(path_to_directory)         


    @classmethod
    def get_a_container(cls,dimension:int = 0, value = 0) -> np.ndarray:
        '''
            Return a np-array for the grid points. Dimension takes the value 0 for scalar, 1 for vector and 2 for tensor.

            This is an auxiliary function. No need to pay extra attention.
        '''
        assert dimension in (0,1,2)
        if dimension == 0:
            return np.zeros((cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion) + value
        elif dimension == 1:
            return np.zeros((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion) + value
        elif dimension == 2:
            return np.zeros((2, 2, cls.CaseInfo.Nx, cls.CaseInfo.Ny), dtype=float_precsion) + value         

    @classmethod
    def save_nparray_to_bin(cls, quantity:np.ndarray, datapath:str):
        with open(datapath, 'wb') as f:
            quantity.tofile(f)  

    @classmethod
    def load_nparray_from_bin(cls, quantity: np.ndarray, datapath:str, dtype=float_precsion) -> np.ndarray:
        shape = quantity.shape
        quantity = np.fromfile(datapath, dtype = dtype).reshape(shape)
        return quantity

    @classmethod
    def base_load_data_all(cls,ID_run:int,ID_frame:int) -> None:
        paths = cls.get_paths()
        data_rootpath = paths['ProcessedData']

        with open(data_rootpath+'/frame_numbers_in_runs.pkl','rb') as f:
            cls.frame_numbers_in_runs = pickle.load(f)
        
        'Grid' 
        X_file = data_rootpath + '/X' + '/uniform_gird_X.bin'
        with open(X_file, 'rb') as f:
            cls.X = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))
        dX_file = data_rootpath + '/X' + '/uniform_gird_dX.bin'
        with open(dX_file, 'rb') as f:
            cls.dX = np.fromfile(f, dtype=float_precsion).reshape((2,))            
        
        'Averaged'
        avg_U_file = data_rootpath + '/avg_U' + '/avg_U.bin'
        with open(avg_U_file, 'rb') as f:
            cls.avg_U = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))
        
        avg_dUdX_file = avg_dUdX_file = data_rootpath + '/avg_dUdX' + '/avg_dUdX.bin'
        with open(avg_dUdX_file, 'rb') as f:
            cls.avg_dUdX = np.fromfile(f, dtype=float_precsion).reshape((2, 2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))            
        
        'Instantaneous'
        run_path = cls.Paths.Run_path_rootword + f'{ID_run}'
        frame_name = cls.Paths.Framedatafile_rootword + f'{ID_frame}.bin'
        
        U_file = data_rootpath + '/U' + run_path + frame_name
        with open(U_file, 'rb') as f:
            cls.U = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))             
        
        fluc_U_file = data_rootpath + '/fluc_U' + run_path + frame_name
        with open(fluc_U_file, 'rb') as f:
            cls.fluc_U = np.fromfile(f, dtype=float_precsion).reshape((2, cls.CaseInfo.Nx, cls.CaseInfo.Ny)) 
        
        dUdX_file = data_rootpath + '/dUdX' + run_path + frame_name
        with open(dUdX_file, 'rb') as f:
            cls.dUdX = np.fromfile(f, dtype=float_precsion).reshape((2,2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))  
        
        fluc_dUdX_file = data_rootpath + '/fluc_dUdX' + run_path + frame_name
        with open(fluc_dUdX_file, 'rb') as f:
            cls.fluc_dUdX = np.fromfile(f, dtype=float_precsion).reshape((2,2, cls.CaseInfo.Nx, cls.CaseInfo.Ny))          
    
    @classmethod
    def get_paths(cls) -> dict:
        paths = {}
        paths['Working'] = cls.Paths.Working_path
        paths['CaseBase'] = paths['Working'] + cls.Paths.Case_foldername
        paths['CurrentCase'] = paths['CaseBase'] + '/' + cls.CaseInfo.CaseName
        paths['RawData'] = paths['CurrentCase'] + cls.Paths.Raw_data_foldername
        paths['ProcessedData'] = paths['CurrentCase'] + cls.Paths.Processed_data_foldername
        paths['LogFile'] = paths['CurrentCase'] + cls.Paths.Log_file_name
        paths['CaseInfo'] = paths['CurrentCase'] + cls.Paths.Caseinfo_file_name
        return paths
    
    # -------------------------------------------------------------------------
    # End of Some tool functions
    # endregion        

# -------------------------------------------------------------------------
# endregion

