''' 
=========================
= Author:   HAN Zexu    =
= Version:  1.2         =
= Date:     2025/04/16  =
=========================
'''

# -------------------------------------------------------------------------
# 01. import
# region
import numpy as np
from scipy.interpolate import griddata
from scipy.stats import gaussian_kde
from scipy.signal import convolve2d
# -------------------------------------------------------------------------
# endregion

# -------------------------------------------------------------------------
# 02. Some parameters
# region
float_precsion = np.float64
int_precsion = np.int32
zero_but_not_zero = 1e-12
zero_in_mm = 1e-7
# -------------------------------------------------------------------------
# endregion

# -------------------------------------------------------------------------
# 03. WelfordStatisticsCalculator
# region
class WelfordStatisticsCalculator:
    '''
        A class to calculate mean value, variance, skewness and kurtosis point by point.

        Cite:
        Welford, B. P. (1962). Note on a method for calculating corrected sums of squares and products. Technometrics, 4(3), 419-420.
    '''
    def __init__(self, shape = 0) -> None:
        self.n:int = 0
        if shape!=0:
            self.ifarray = True
            self.mean = np.zeros(shape,dtype=float_precsion)
            self.M2 = np.zeros(shape,dtype=float_precsion)
            self.M3 = np.zeros(shape,dtype=float_precsion)
            self.M4 = np.zeros(shape,dtype=float_precsion)
        else:
            self.ifarray = False
            self.mean = float_precsion(0.0)
            self.M2 = float_precsion(0.0)
            self.M3 = float_precsion(0.0)
            self.M4 = float_precsion(0.0)        
    
    def add_point(self, x) -> None:
        if self.ifarray == True:
            assert x.shape == self.mean.shape
        self.n += 1
        delta = (x - self.mean)
        delta_n = delta / self.n
        delta_n2 = delta_n * delta_n

        term1 = delta * delta_n * (self.n - 1)

        self.mean += delta_n
        self.M4 += term1 * delta_n2 * (self.n * self.n - 3 * self.n + 3) + 6 * delta_n2 * self.M2 - 4 * delta_n * self.M3
        self.M3 += term1 * delta_n * (self.n - 2) - 3 * delta_n * self.M2
        self.M2 += term1

    def get_mean(self):
        return self.mean

    def get_variance(self):
        if self.n < 2:
            return float('nan')  
        return self.M2 / (self.n - 1) 

    def get_skewness(self):
        if self.n < 3:
            return float('nan')
        unbiased_factor = np.sqrt(self.n * (self.n - 1)) / (self.n - 2)
        return unbiased_factor * self.M3 / (self.M2 ** 1.5)

    def get_flatness(self):
        if self.n < 4:
            return float('nan')
        unbiased_factor = (self.n * (self.n + 1) * (self.n - 1)) / ((self.n - 2) * (self.n - 3))
        return unbiased_factor * self.M4 / (self.M2 ** 2)
    
    def get_result(self):
        return self.get_mean, self.get_variance, self.get_skewness, self.get_flatness
    
class ShortWelfordStatisticsCalculator:
    '''
        A class to calculate mean value and variance point by point.

        Cite:
        Welford, B. P. (1962). Note on a method for calculating corrected sums of squares and products. Technometrics, 4(3), 419-420.
    '''
    def __init__(self, shape = 0) -> None:
        self.n:int = 0
        if shape != 0:
            self.ifarray = True
            self.mean = np.zeros(shape,dtype=float_precsion)
            self.M2 = np.zeros(shape,dtype=float_precsion)
        else:
            self.ifarray = False
            self.mean = float_precsion(0.0)  
            self.M2 = float_precsion(0.0)  
    
    def add_point(self, x) -> None:
        if self.ifarray == True:
            assert x.shape == self.mean.shape
        self.n += 1
        delta = (x - self.mean)
        delta_n = delta / self.n

        term1 = delta * delta_n * (self.n - 1)
        self.mean += delta_n
        self.M2 += term1

    def get_mean(self):
        return self.mean

    def get_variance(self):
        if self.n < 2:
            return float('nan')  
        return self.M2 / self.n 

    def get_result(self):
        return self.get_mean, self.get_variance

# -------------------------------------------------------------------------
# endregion

# -------------------------------------------------------------------------
# 04. One-dimensional operations
# region
def central_stepping_indexs(length:int, version = 'Han') -> np.ndarray:
    indexs = np.zeros((length,2),dtype=int_precsion)
    assert version == 'Han' or 'WatanabeSensei'
    if version == 'Han':
        for i in range(1,length):
            'Han_s version'
            indexs[i,0] = int((-i)/2)  #leftside
            indexs[i,1] = int((i-1)/2+1)    #rightside
    else:
        for i in range(1,length):
            if(i%2 == 0):
                indexs[i,0] = -int((i)/2)  #leftside
                indexs[i,1] = int(i/2)    #rightside
            else:
                indexs[i,0] = -int((i+1)/2)  #leftside
                indexs[i,1] = int((i+1)/2)-1    #rightside
    return indexs 

def moving_average(arr:np.ndarray, window_size:int_precsion):
    assert window_size > 1
    assert isinstance(arr, np.ndarray)
    assert arr.ndim == 1

    shifts = central_stepping_indexs(window_size)[-1]
    left_dir = -shifts[0]
    right_dir = shifts[1]

    # left_dir = int((shifts)/2)
    # right_dir = int((shifts-1)/2+1)

    tmp = np.zeros(arr.shape)
    tmp += arr
    for i in range(1,left_dir+1):
        tmp[:-i] += arr[i:]
    for i in range(1,right_dir+1):
        tmp[i:] += arr[:-i]
    tmp[0:right_dir] = np.nan
    tmp[len(tmp)-left_dir:] = np.nan
    return tmp/window_size

class np_fft():
    def __init__(self,signal:np.ndarray, dx_in_mm:float_precsion):
        assert isinstance(signal, np.ndarray)
        assert signal.ndim == 1
        self.signal = signal
        self.dx_in_m = dx_in_mm/1000
        self.result = np.zeros(signal.shape)
        self.wavenumber = np.zeros(signal.shape)
    def fft(self):
        
        # window = np.hamming(len(self.signal))
        # windowed_signal = self.signal * window
        # result = np.fft.fft(windowed_signal) * 2.67
        result = np.fft.fft(self.signal)

        self.result = np.abs(result) * np.abs(result) / np.pi / len(self.signal) *self.dx_in_m
        self.wavenumber = np.fft.fftfreq(len(self.signal),self.dx_in_m)
        self.wavenumber = self.wavenumber *2 *np.pi
    def get_result(self):
        return self.result[1:len(self.signal)//2], self.wavenumber[1:len(self.signal)//2]

class least_squared_fitting():
    def __init__(self, x:np.ndarray, y:np.ndarray, order = 1):
        assert len(x) == len(y)
        self.x = x
        self.y = y
        self.order = order
        
        self.effective_stepping_index:tuple[int] = None
        self.y_fit = None
        self.result_a = None
        self.result_b = None
        self.coeffs = None
        self.result_r = None
    
    def calculate(self):
        self.coeffs = np.polyfit(self.x, self.y, self.order)
        self.result_a, self.result_b = self.coeffs[0], self.coeffs[1]
        self.y_fit = np.polyval(self.coeffs, self.x)
        self.result_r = np.corrcoef(self.y, self.y_fit)[0,1]

    def effective_cal(self, ref_r2 = 0.9):
        origin_x = self.x
        origin_y = self.y
        
        origin_len = len(self.x)
        central_pos = int(origin_len/2)
        indexs = central_stepping_indexs(origin_len)
        for index in indexs[::-1]:
            left = central_pos + index[0]
            right = central_pos + index[1]
            self.x = origin_x[left:right]
            self.y = origin_y[left:right]
            self.effective_stepping = (index[0],index[1])
            self.calculate()
            print(self.result_r)
            if self.result_r**2 > ref_r2:
                break

# -------------------------------------------------------------------------
# endregion

# -------------------------------------------------------------------------
# 05. Two-dimensional operations
# region
def lagrange_interpolate_2D_4points_scalar(grid1:np.ndarray, grid2: np.ndarray, scalar1: np.ndarray) -> np.ndarray:
    '''
    grid1: origin uniform grid, grid2: target grid, scalar1: data value in the origin grid.

    As for grids of different sizes, you can still interpolate it by adding irrelevant elements.

    This function try to run faster at the expense of memory and store some mapping relations into numpy arrays.
    Thus it may be obscure.
    '''
    Nx = scalar1.shape[0]
    Ny = scalar1.shape[1]  
            
    x_read = grid1[0] # x1[0:Nx-1][0:Ny-1]
    y_read = grid1[1] # y1[0:Nx-1][0:Ny-1]
    x = grid2[0,:,0]
    y = grid2[1,0,:]
    
    'Notice here that we assume grid1 is an nearly uniform grid'
    xzero = x_read[0, 0]
    yzero = y_read[0, 0]
    dx = (x_read[-1, -1] - x_read[0, 0]) / (Nx-1)
    dy = (y_read[-1, -1] - y_read[0, 0]) / (Ny-1)

    Nx_2 = grid2.shape[1]
    Ny_2 = grid2.shape[2]  
    scalar2 = np.zeros((Nx_2,Ny_2),dtype=float_precsion)

    for j in range(Ny_2):
        for i in range(Nx_2):
            i_ip = int( (x[i]-xzero)/dx +1)
            j_ip = int( (y[j]-yzero)/dy +1)
            if 0 <= i_ip-2 and i_ip+1 <= Nx-1 and 0 <= j_ip-2 and j_ip+1 <= Ny-1:
                x1 = x_read[i_ip-2,j_ip]
                x2 = x_read[i_ip-1,j_ip]
                x3 = x_read[i_ip  ,j_ip]
                x4 = x_read[i_ip+1,j_ip]
                
                y1 = y_read[i_ip, j_ip-2]
                y2 = y_read[i_ip, j_ip-1]
                y3 = y_read[i_ip, j_ip  ]
                y4 = y_read[i_ip, j_ip+1]

                ax1 = (x[i]-x2)*(x[i]-x3)*(x[i]-x4) /(x1-x2) /(x1-x3) /(x1-x4)
                ax2 = (x[i]-x1)*(x[i]-x3)*(x[i]-x4) /(x2-x1) /(x2-x3) /(x2-x4)
                ax3 = (x[i]-x1)*(x[i]-x2)*(x[i]-x4) /(x3-x1) /(x3-x2) /(x3-x4)
                ax4 = (x[i]-x1)*(x[i]-x2)*(x[i]-x3) /(x4-x1) /(x4-x2) /(x4-x3)
                
                by1 = (y[j]-y2)*(y[j]-y3)*(y[j]-y4) /(y1-y2) /(y1-y3) /(y1-y4)
                by2 = (y[j]-y1)*(y[j]-y3)*(y[j]-y4) /(y2-y1) /(y2-y3) /(y2-y4)
                by3 = (y[j]-y1)*(y[j]-y2)*(y[j]-y4) /(y3-y1) /(y3-y2) /(y3-y4)
                by4 = (y[j]-y1)*(y[j]-y2)*(y[j]-y3) /(y4-y1) /(y4-y2) /(y4-y3)


                scalar2[i,j] = (
                    by1*(
                        ax1 * scalar1[i_ip-2,j_ip-2]+
                        ax2 * scalar1[i_ip-1,j_ip-2]+
                        ax3 * scalar1[i_ip  ,j_ip-2]+
                        ax4 * scalar1[i_ip+1,j_ip-2]
                    )+
                    by2*(
                        ax1 * scalar1[i_ip-2,j_ip-1]+
                        ax2 * scalar1[i_ip-1,j_ip-1]+
                        ax3 * scalar1[i_ip  ,j_ip-1]+
                        ax4 * scalar1[i_ip+1,j_ip-1]
                    )+
                    by3*(
                        ax1 * scalar1[i_ip-2,j_ip  ]+
                        ax2 * scalar1[i_ip-1,j_ip  ]+
                        ax3 * scalar1[i_ip  ,j_ip  ]+
                        ax4 * scalar1[i_ip+1,j_ip  ]
                    )+
                    by4*(
                        ax1 * scalar1[i_ip-2,j_ip+1]+
                        ax2 * scalar1[i_ip-1,j_ip+1]+
                        ax3 * scalar1[i_ip  ,j_ip+1]+
                        ax4 * scalar1[i_ip+1,j_ip+1]
                    )
                )
            
            elif i_ip > Nx-1 or j_ip > Ny-1:
                scalar2[i,j] = np.nan
            elif i_ip-1 < 0 or j_ip-1 < 0:
                scalar2[i,j] = np.nan        
            
            else:
                ax = (x_read[i_ip,j_ip]-x[i])/(x[1]-x[0])
                by = (y_read[i_ip,j_ip]-y[j])/(y[1]-y[0])
                scalar2[i,j] = (
                    by*(
                        ax * scalar1[i_ip-1,j_ip-1]+
                        (1-ax) * scalar1[i_ip,j_ip-1]
                    )+
                    (1-by)*(
                        ax * scalar1[i_ip-1,j_ip]+
                        (1-ax) * scalar1[i_ip,j_ip]
                    )
                )   
    return scalar2

def scipy_interpolate_2D_4points_scalar(grid1:np.ndarray, grid2: np.ndarray, scalar1: np.ndarray, method:str = 'linear') -> np.ndarray:
    points = np.array([grid1[0].flatten(), grid1[1].flatten()]).T
    values = scalar1.flatten()
    points_target = np.array([grid2[0].flatten(), grid2[1].flatten()]).T
    Z_interpolated = griddata(points, values, points_target, method = method).reshape(grid2[0].shape)
    return Z_interpolated

def scalar_field_5points_stencil(arr:np.ndarray, delta_x:float_precsion, delta_y:float_precsion) -> np.ndarray:
    '''
    Hello.

    Parameters:
    arr: A scalar field.
    delta: The step size(i.e. dx). 
    '''
    tmp_array = np.full( (2,) + arr.shape, np.nan)
    tmp_array[0][2:-2,2:-2] = (-arr[4:,2:-2]+8.0*arr[3:-1,2:-2]-8.0*arr[1:-3,2:-2]+arr[:-4,2:-2])/(12.0*delta_x)
    tmp_array[1][2:-2,2:-2] = (-arr[2:-2,4:]+8.0*arr[2:-2,3:-1]-8.0*arr[2:-2,1:-3]+arr[2:-2,:-4])/(12.0*delta_y)
    return tmp_array


def nanmean_filter2d(data, kernel_size=5, kernel=None):
    if kernel is None:
        kernel = np.ones((kernel_size, kernel_size), dtype=float)

    data_filled = np.nan_to_num(data, nan=0.0)
    mask = ~np.isnan(data)

    summed = convolve2d(data_filled, kernel, mode='same', boundary='fill', fillvalue=np.nan)
    counts = convolve2d(mask.astype(float), kernel, mode='same', boundary='fill', fillvalue=np.nan)

    with np.errstate(invalid='ignore', divide='ignore'):
        result = summed / counts
    result[counts == 0] = np.nan

    return result


def shift_field(field:np.ndarray, shift_x:int, shift_y:int, boundary_value:float_precsion = np.nan) -> np.ndarray:
    '''
    Example: (in the imagined 2d grid instead of numpy array)
    0 1 2 3  shift_x =  1   nan nan nan nan  
    4 5 6 7  shift_y = -1   nan 0 1 2
    7 8 9 10 ------------>  nan 4 5 6
    '''
    shifted_field = np.full(field.shape, boundary_value,dtype=float_precsion)

    if shift_x > 0 and shift_y > 0:
        shifted_field[shift_x:,shift_y:] = field[:-shift_x,:-shift_y]
    elif shift_x < 0 and shift_y > 0:
        shift_x = -shift_x
        shifted_field[:-shift_x,shift_y:] = field[shift_x:,:-shift_y]
    elif shift_x > 0 and shift_y < 0:
        shift_y = -shift_y
        shifted_field[shift_x:,:-shift_y] = field[:-shift_x,shift_y:]
    elif shift_x < 0 and shift_y < 0:
        shift_x = -shift_x
        shift_y = -shift_y
        shifted_field[:-shift_x,:-shift_y] = field[shift_x:,shift_y:]
    elif shift_x == 0 and shift_y > 0:
        shifted_field[:,shift_y:] = field[:,:-shift_y]
    elif shift_x == 0 and shift_y < 0:
        shift_y = -shift_y
        shifted_field[:,:-shift_y] = field[:,shift_y:]
    elif shift_x > 0 and shift_y == 0:
        shifted_field[shift_x:,:] = field[:-shift_x,:]
    elif shift_x < 0 and shift_y == 0:
        shift_x = -shift_x
        shifted_field[:-shift_x,:] = field[shift_x:,:]
    else:
        shifted_field[:,:] = field[:,:]
    return shifted_field

# -------------------------------------------------------------------------
# endregion

# -------------------------------------------------------------------------
# 06. Probability density function
# region
class ProbabilityDensity():
    def __init__(self):
        self.point_list = []
        self.ws = WelfordStatisticsCalculator()
        self.KDE_x = None
        self.KDE_y = None
    def add_point(self, points):
        if isinstance(points, np.ndarray):
            point_list = points.flatten().tolist()
        elif isinstance(points, list):
            point_list = points
        else:
            raise ValueError("Numpy's array or Python's list!")        
        self.point_list = self.point_list + point_list
        for data_point in point_list:
            self.ws.add_point(data_point)

    def process(self, KDE_points = 1000):
        point_np = np.array(self.point_list)
        kde = gaussian_kde(point_np)
        self.KDE_x = np.linspace(min(point_np), max(point_np), KDE_points)
        self.KDE_y = kde(self.KDE_x)
    def normalize(self):
        self.KDE_x = (self.KDE_x - self.ws.get_mean())/np.sqrt(self.ws.get_variance())
        self.KDE_y = self.KDE_y * np.sqrt(self.ws.get_variance())

# -------------------------------------------------------------------------
# endregion
